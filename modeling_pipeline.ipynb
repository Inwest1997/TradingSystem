{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pda\n",
    "import tensorflow as tf\n",
    "\n",
    "from index import *\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "class PTDataset(Dataset):\n",
    "    '''\n",
    "    데이터 셋에서는 Adj Close만 가져오는 걸로\n",
    "    stock_name\n",
    "    target -> position or price\n",
    "    window size\n",
    "    scaling -> each features and target\n",
    "    indicators(technical and economic)\n",
    "\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                    ticker, \n",
    "                    window= 20, \n",
    "                    target = 'Adj Close', \n",
    "                    scaling = False, \n",
    "                    target_gen = None, \n",
    "                    drop_feature = None, \n",
    "                    mode = 'train', \n",
    "                    split = 0.7) :\n",
    "                    \n",
    "        super(PTDataset).__init__()\n",
    "        self.ticker = ticker\n",
    "        df = yf.Ticker(self.ticker).history(period=\"max\",auto_adjust = False)[['Open','High','Low','Adj Close','Volume']]\n",
    "        self.target = target\n",
    "        self.df = read_all(df)\n",
    "        if drop_feature != None:\n",
    "            self.df.drop(drop_feature, axis = 1)\n",
    "        self.target_generator(target_gen)\n",
    "        if scaling == True:\n",
    "            self.scaler()\n",
    "        self.df = self.df.dropna(axis = 0)\n",
    "        self.columns = self.df.columns\n",
    "        self.period = (self.df.index.max()-self.df.index.min()).days\n",
    "        if mode == 'train':\n",
    "            self.df = self.df.iloc[:int(split*len(self.df))]\n",
    "        else:\n",
    "            self.df = self.df.iloc[:int(split*len(self.df))]\n",
    "        self.X, self.y = self.my_window_data(window)\n",
    "\n",
    "        self.X = torch.tensor([self.X], dtype = torch.float32)\n",
    "        self.y = torch.tensor([self.y], dtype = torch.float32)\n",
    "    def my_window_data(self, window_size):\n",
    "        X_list = [self.df.iloc[i:i+window_size] for i in range(len(self.df) - window_size-1)]\n",
    "        y_list = [self.df.iloc[i+window_size][self.target] for i in range(len(self.df) - window_size-1)]\n",
    "        return  np.array(X_list), np.array(y_list).reshape(-1)\n",
    "\n",
    "    def scaler(self):\n",
    "        scaler = MinMaxScaler()\n",
    "        self.df = pd.DataFrame(columns = self.df.columns, data = scaler.fit_transform(self.df))\n",
    "\n",
    "    def target_generator(self, target_gen):\n",
    "        if target_gen == None:\n",
    "            pass\n",
    "        elif target_gen == 'trend':\n",
    "            self.df[self.target] = [1 if self.df[self.target].diff().iloc[i]>0 else 0 for i in range(len(self.df))]\n",
    "        else:\n",
    "            self.df[self.target] = [  1 if self.df[self.target].diff(1).iloc[i]>0 and self.df[self.target].diff(-1).iloc[i]>0\n",
    "                                else -1 if self.df[self.target].diff(1).iloc[i]<0 and self.df[self.target].diff(-1).iloc[i]<0\n",
    "                                else 0 for i in range(len(self.df))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, i): \n",
    "        return self.X[i], self.y[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFDataset(tf.keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    Custom data generator class for Digits dataset\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 ticker,\n",
    "                 window = 20,\n",
    "                 period = 1,\n",
    "                 target = 'Adj Close',\n",
    "                 scaling = False, \n",
    "                 target_gen = None, \n",
    "                 drop_feature = None, \n",
    "                 batch_size: int=64,\n",
    "                 mode = 'train', \n",
    "                 split = 0.7):\n",
    "        self.ticker = ticker\n",
    "        df = yf.Ticker(self.ticker).history(period=\"max\",auto_adjust = False)[['Open','High','Low','Adj Close','Volume']]\n",
    "        self.target = target\n",
    "        self.df = read_all(df)\n",
    "        if drop_feature != None:\n",
    "            self.df.drop(drop_feature, axis = 1)\n",
    "        self.df = self.df.dropna(axis = 0)\n",
    "        if mode == 'train':\n",
    "            self.df = self.df.iloc[:int(split*len(self.df))]\n",
    "        else:\n",
    "            self.df = self.df.iloc[:int(split*len(self.df))]\n",
    "\n",
    "        self.X, self.y = self.df, self.df[[self.target]]\n",
    "\n",
    "        self.target_generator(target_gen)\n",
    "        if scaling == True:\n",
    "            self.scaler()\n",
    "        self.columns = self.df.columns\n",
    "        self.period = (self.df.index.max()-self.df.index.min()).days\n",
    "        self.batch_size = batch_size\n",
    "        self.X, self.y = self.my_window_data(window_size = window, for_period=period)\n",
    "\n",
    "    def my_window_data(self, window_size, for_period):\n",
    "        X_list = [self.X.iloc[i:i+window_size] for i in range(len(self.X) - window_size-for_period)]\n",
    "        y_list = [self.y[self.target].iloc[i+window_size:i+window_size+for_period].values for i in range(len(self.y) - window_size-for_period)]\n",
    "        return  np.array(X_list), np.array(y_list)\n",
    "\n",
    "    def scaler(self):\n",
    "        scaler = MinMaxScaler()\n",
    "        self.X = pd.DataFrame(columns = self.X.columns, data = scaler.fit_transform(self.X))\n",
    "        self.y = pd.DataFrame(columns = self.X.columns, daat = np.log1p(self.y))\n",
    "\n",
    "    def target_generator(self, target_gen):\n",
    "\n",
    "        if target_gen == None:\n",
    "            pass\n",
    "        elif target_gen == 'trend':\n",
    "            self.y[self.target] = ['up' if self.y[self.target].diff().iloc[i]>0 else 'down' for i in range(len(self.y[self.target]))]\n",
    "            self.y = pd.get_dummies(self.y[self.target])\n",
    "            # self.y = tf.keras.utils.to_categorical(self.y[self.target],  num_classes=2)\n",
    "\n",
    "        else:\n",
    "            self.y[self.target] = [  'buy' if self.y[self.target].diff(1).iloc[i]>0 and self.y[self.target].diff(-1).iloc[i]>0\n",
    "                                else 'sell' if self.y[self.target].diff(1).iloc[i]<0 and self.y[self.target].diff(-1).iloc[i]<0\n",
    "                                else 'hold' for i in range(len(self.y[self.target]))]\n",
    "            self.y = pd.get_dummies(self.y[self.target])\n",
    "            \n",
    "    def __len__(self):\n",
    "        return np.math.ceil(len(self.X) / self.batch_size)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Returns a batch of data\n",
    "        \"\"\"\n",
    "        batch_X = self.X[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        batch_y = self.y[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "\n",
    "        return batch_X, batch_y\n",
    "    def only_data(self):\n",
    "        return self.X, self.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PTDataset(ticker = 'AAPL', drop_feature=['Open', 'Close', 'High'], mode = 'train')\n",
    "# train_dataloader = data.DataLoader(train_dataset, batch_size=20)\n",
    "test_dataset = PTDataset(ticker = 'AAPL', drop_feature=['Open', 'Close', 'High'], mode = 'test')\n",
    "# test_dataloader = data.DataLoader(test_dataset, batch_size=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TFDataset(ticker = 'AAPL', mode = 'train', period=5)\n",
    "X, y = td.only_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3.14731985e-01, 3.34820986e-01, 3.12500000e-01, ...,\n",
       "         1.61849867e+10, 2.52797294e-01, 2.53152910e-01],\n",
       "        [3.39286000e-01, 3.39286000e-01, 3.34820986e-01, ...,\n",
       "         1.60858947e+10, 2.55641657e-01, 2.55108374e-01],\n",
       "        [3.41518015e-01, 3.45981985e-01, 3.32589000e-01, ...,\n",
       "         1.60039667e+10, 2.59197274e-01, 2.56975055e-01],\n",
       "        ...,\n",
       "        [3.05804014e-01, 3.10268015e-01, 3.03570986e-01, ...,\n",
       "         1.60136127e+10, 2.40886450e-01, 2.40797643e-01],\n",
       "        [3.03570986e-01, 3.03570986e-01, 2.87945986e-01, ...,\n",
       "         1.60353872e+10, 2.38753119e-01, 2.39553215e-01],\n",
       "        [2.94643015e-01, 2.99106985e-01, 2.86830008e-01, ...,\n",
       "         1.60555377e+10, 2.38753119e-01, 2.38842079e-01]],\n",
       "\n",
       "       [[3.39286000e-01, 3.39286000e-01, 3.34820986e-01, ...,\n",
       "         1.60858947e+10, 2.55641657e-01, 2.55108374e-01],\n",
       "        [3.41518015e-01, 3.45981985e-01, 3.32589000e-01, ...,\n",
       "         1.60039667e+10, 2.59197274e-01, 2.56975055e-01],\n",
       "        [3.37054014e-01, 3.41518015e-01, 3.30356985e-01, ...,\n",
       "         1.59449534e+10, 2.63641703e-01, 2.58397347e-01],\n",
       "        ...,\n",
       "        [3.03570986e-01, 3.03570986e-01, 2.87945986e-01, ...,\n",
       "         1.60353872e+10, 2.38753119e-01, 2.39553215e-01],\n",
       "        [2.94643015e-01, 2.99106985e-01, 2.86830008e-01, ...,\n",
       "         1.60555377e+10, 2.38753119e-01, 2.38842079e-01],\n",
       "        [2.96875000e-01, 3.08036000e-01, 2.94643015e-01, ...,\n",
       "         1.60723506e+10, 2.39108658e-01, 2.38219827e-01]],\n",
       "\n",
       "       [[3.41518015e-01, 3.45981985e-01, 3.32589000e-01, ...,\n",
       "         1.60039667e+10, 2.59197274e-01, 2.56975055e-01],\n",
       "        [3.37054014e-01, 3.41518015e-01, 3.30356985e-01, ...,\n",
       "         1.59449534e+10, 2.63641703e-01, 2.58397347e-01],\n",
       "        [3.34820986e-01, 3.39286000e-01, 3.30356985e-01, ...,\n",
       "         1.58910186e+10, 2.67552841e-01, 2.59641773e-01],\n",
       "        ...,\n",
       "        [2.94643015e-01, 2.99106985e-01, 2.86830008e-01, ...,\n",
       "         1.60555377e+10, 2.38753119e-01, 2.38842079e-01],\n",
       "        [2.96875000e-01, 3.08036000e-01, 2.94643015e-01, ...,\n",
       "         1.60723506e+10, 2.39108658e-01, 2.38219827e-01],\n",
       "        [3.08036000e-01, 3.10268015e-01, 2.94643015e-01, ...,\n",
       "         1.60787637e+10, 2.39108658e-01, 2.38753115e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[2.02560711e+01, 2.04285717e+01, 2.00928574e+01, ...,\n",
       "         1.58126421e+11, 1.71230934e+01, 1.68398203e+01],\n",
       "        [2.05678577e+01, 2.10714283e+01, 2.04896431e+01, ...,\n",
       "         1.58040693e+11, 1.75030231e+01, 1.69702621e+01],\n",
       "        [2.10553570e+01, 2.10864296e+01, 2.07178574e+01, ...,\n",
       "         1.57961114e+11, 1.76200432e+01, 1.70991068e+01],\n",
       "        ...,\n",
       "        [1.87500000e+01, 1.91035709e+01, 1.85803566e+01, ...,\n",
       "         1.57417053e+11, 1.61629183e+01, 1.63449897e+01],\n",
       "        [1.89810715e+01, 1.90607147e+01, 1.87678566e+01, ...,\n",
       "         1.57330660e+11, 1.60849672e+01, 1.63066588e+01],\n",
       "        [1.89285717e+01, 1.89357147e+01, 1.85314293e+01, ...,\n",
       "         1.57201532e+11, 1.60360708e+01, 1.62283082e+01]],\n",
       "\n",
       "       [[2.05678577e+01, 2.10714283e+01, 2.04896431e+01, ...,\n",
       "         1.58040693e+11, 1.75030231e+01, 1.69702621e+01],\n",
       "        [2.10553570e+01, 2.10864296e+01, 2.07178574e+01, ...,\n",
       "         1.57961114e+11, 1.76200432e+01, 1.70991068e+01],\n",
       "        [2.06167850e+01, 2.09214287e+01, 2.04378567e+01, ...,\n",
       "         1.57906414e+11, 1.77553696e+01, 1.72220850e+01],\n",
       "        ...,\n",
       "        [1.89810715e+01, 1.90607147e+01, 1.87678566e+01, ...,\n",
       "         1.57330660e+11, 1.60849672e+01, 1.63066588e+01],\n",
       "        [1.89285717e+01, 1.89357147e+01, 1.85314293e+01, ...,\n",
       "         1.57201532e+11, 1.60360708e+01, 1.62283082e+01],\n",
       "        [1.83024998e+01, 1.85596428e+01, 1.82228565e+01, ...,\n",
       "         1.57028950e+11, 1.60946732e+01, 1.61855546e+01]],\n",
       "\n",
       "       [[2.10553570e+01, 2.10864296e+01, 2.07178574e+01, ...,\n",
       "         1.57961114e+11, 1.76200432e+01, 1.70991068e+01],\n",
       "        [2.06167850e+01, 2.09214287e+01, 2.04378567e+01, ...,\n",
       "         1.57906414e+11, 1.77553696e+01, 1.72220850e+01],\n",
       "        [2.10792866e+01, 2.12232132e+01, 2.09017868e+01, ...,\n",
       "         1.57902949e+11, 1.79252792e+01, 1.73832718e+01],\n",
       "        ...,\n",
       "        [1.89285717e+01, 1.89357147e+01, 1.85314293e+01, ...,\n",
       "         1.57201532e+11, 1.60360708e+01, 1.62283082e+01],\n",
       "        [1.83024998e+01, 1.85596428e+01, 1.82228565e+01, ...,\n",
       "         1.57028950e+11, 1.60946732e+01, 1.61855546e+01],\n",
       "        [1.85839291e+01, 1.87232132e+01, 1.85253563e+01, ...,\n",
       "         1.56833626e+11, 1.61029047e+01, 1.61559156e+01]]])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24177493,  0.24177493,  0.23910849,  0.24355341,  0.24888638],\n",
       "       [ 0.24177493,  0.23910849,  0.24355341,  0.24888638,  0.24710876],\n",
       "       [ 0.23910849,  0.24355341,  0.24888638,  0.24710876,  0.23644206],\n",
       "       ...,\n",
       "       [15.95062447, 15.97642231, 15.75620461, 15.81947327, 15.65146828],\n",
       "       [15.97642231, 15.75620461, 15.81947327, 15.65146828, 16.34498978],\n",
       "       [15.75620461, 15.81947327, 15.65146828, 16.34498978, 16.86282349]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (64, 20, 25) (64, 5)\n",
      "1 (64, 20, 25) (64, 5)\n",
      "2 (64, 20, 25) (64, 5)\n",
      "3 (64, 20, 25) (64, 5)\n",
      "4 (64, 20, 25) (64, 5)\n",
      "5 (64, 20, 25) (64, 5)\n",
      "6 (64, 20, 25) (64, 5)\n",
      "7 (64, 20, 25) (64, 5)\n",
      "8 (64, 20, 25) (64, 5)\n",
      "9 (64, 20, 25) (64, 5)\n",
      "10 (64, 20, 25) (64, 5)\n"
     ]
    }
   ],
   "source": [
    "for idx,( X, y )in enumerate(train_loader):\n",
    "    print(idx, X.shape, y.shape)\n",
    "    if idx ==10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.funciton\n",
    "def train(model, optimizer, loss_fn, en_epoch):\n",
    "    train_set = TFDataset( ticker = 'AAPL', period=5)\n",
    "    for X_batch, y_batch in train_set:\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss]+model.losses)\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b7f90f3ffd1b2a60fee91aee39c73355e94a75c9e00035a66944cc7ed4c1221"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
